{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment is done to show that plain Python is faster than Pandas if not comparable. It is done in python 3.12 and pandas 2.2.2:\n",
    "```bash\n",
    "conda create -n fairness-panda python=3.12 pandas=2.2.2 jupyter\n",
    "conda activate fairness-panda\n",
    "pip install fairness-checker\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fairness_checker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = fairness_csv_checker(\"compas-scores-two-years.csv\", verbose=False)\n",
    "race = 'Native American'\n",
    "sex = 'Male'\n",
    "degree = 'M'\n",
    "age = 'Greater than 45'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using plain Python, this takes about 0.3 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    c.disparate_impact(0.8, lambda row: row['sex'] == sex, lambda row: row['score_text'] in {'Medium', 'High'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same row predicate with Pandas, this takes around 12 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "privileged_predicate = lambda row: row['sex'] == sex\n",
    "positive_predicate = lambda row: row['score_text'] in {'Medium', 'High'}\n",
    "for _ in range(100):\n",
    "    privileged = df[df.apply(lambda row: privileged_predicate(row), axis=1)]\n",
    "    unprivileged = df[df.apply(lambda row: not privileged_predicate(row), axis=1)]\n",
    "\n",
    "    privileged_Y_result = privileged[privileged.apply(lambda row: positive_predicate(row), axis=1)]\n",
    "    unprivileged_Y_result = unprivileged[unprivileged.apply(lambda row: positive_predicate(row), axis=1)]\n",
    "\n",
    "    privileged_percentage = len(privileged_Y_result) / len(privileged)\n",
    "    unprivileged_percentage = len(unprivileged_Y_result) / len(unprivileged)\n",
    "\n",
    "    measure = unprivileged_percentage / privileged_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the column predicate with Pandas, this takes around 1 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "privileged_predicate = lambda x: x == sex\n",
    "positive_predicate = lambda x: x in {'Medium', 'High'}\n",
    "for _ in range(100):\n",
    "    privileged = df[df['sex'].apply(lambda row: privileged_predicate(row))]\n",
    "    unprivileged = df[df['sex'].apply(lambda row: not privileged_predicate(row))]\n",
    "\n",
    "    privileged_Y_result = privileged[privileged['score_text'].apply(lambda row: positive_predicate(row))]\n",
    "    unprivileged_Y_result = unprivileged[unprivileged['score_text'].apply(lambda row: positive_predicate(row))]\n",
    "\n",
    "    privileged_percentage = len(privileged_Y_result) / len(privileged)\n",
    "    unprivileged_percentage = len(unprivileged_Y_result) / len(unprivileged)\n",
    "\n",
    "    measure = unprivileged_percentage / privileged_percentage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
